---
title: 头戴式混合现实
tags: MR SLAM
edit: 2020-03-01
categories: 技术类
status: Paused
mathjax: true
highlight: true
mermaid: true
description: 主要是写一些头戴式MR方面的思考以及遇到的坑，比如到底要不要使用深度传感器，合适的落地场景，每个传感器选择和使用的注意项，解析SLAM算法在MR中的结构。另外和手机端MR做比较，最后预测未来MR的发展趋势
---

# 深度传感器的必要性？
## 主流方案：
首先我们来讲一下移动端的深度传感，一般有结构光、TOF、双目3种主流方案：
- 结构光(Structured Light)：结构光投射特定的光信息到物体表面后，由摄像头采集。根据物体造成的光信号的变化来计算物体的位置和深度等信息，进而复原整个三维空间。
- TOF(Time Of Flight，飞行时间)：通过专有传感器，捕捉近红外光从发射到接收的飞行时间，判断物体距离。
- 双目测距(Stereo System)：利用双摄像头拍摄物体，再通过三角形原理计算物体距离。
可以说，既有的三种方案各有所长，TOF的响应速度快、精度高，不易受环境光线干扰，但是功耗和成本都比较大；结构光的工业化应用较多；双目立体成像更适合室外强光条件和高分辨率应用，目前主要应用在机器人视觉、自动驾驶等方面。

## 不同角度：
- 算法人员：产品要做一个地面检测的功能，单靠视觉方案？不可能的，地面都没什么特征信息，很容易误判，我们需要深度传感器。
- 硬件人员：加个深度传感多耗电又发热啊，处理器压力也大，配套设备要上来。
- 产品经理：加上深度传感器可以扩展很多功能，但是成本怎么权衡，只能出旗舰版了。
- 市场需求：手机版都加了深度感应看来技术可行，那头戴式加上也可以啊。

## 落地场景：
个人思考，头戴式的移动端是要贴皮肤的，切忌牺牲用户舒适度来换取功能提升，不管是从机子重量，温度和耗电量角度，都是对硬件的高要求。此外，头戴式的移动端在哪些场景需要深度感应器？主要是地面检测辅助定位，3D手势识别辅助真的是市场最急需的吗？
- 从教育角度，如果一个学生看书可以在空中浮现虚拟影像辅助他们，练习英语口语可以看到一个虚拟人和你通过麦克风练习是不是可以了？
- 从游戏的角度，我们非要在没把室内固定场景做稳定的情况下把场景移植到室外不可控环境吗？如果在室内，桌面游戏，贴墙感难道不能通过事先让消费者带着设备转几圈扫描一下获取整个场景深度信息吗？室内场景可控性高一些，这样深度传感器的优势就不明显了。
- 从商业角度，远程会议的主要功能是增加会议人员之间的互动感，这个需要靠沉浸感，模型真实度（暂时不考虑真实3D人体扫描传输，成本过高，摄像头捕捉表情驱动模型更具有实时性）一起完成，人之间的距离是可以自设的，手势和定位不是核心问题。
- 从工业角度，指望一个工人在现场记忆好几个3D手势，而且还必须把手放在眼前才能检测到？那还不如直接给他们一个控制器手柄，拿到的时候就能马上适应。

所以，从商业落地的角度看，除了给开发人员的旗舰版需要深度传感器，大部分真的没必要。市场的产品是需要不断试水的，每一代在前一代的基础上优化增加功能，但前提是每一代产品功能稳定。

# 传感器注意事项？
## 高质量相机的重要性
重要的话说三遍：良好的输入端图像是头戴MR设备定位准确的前提。良好的输入端图像是头戴MR设备定位准确的前提。良好的输入端图像是头戴MR设备定位准确的前提。
- Rolling shutter vs Global shutter
但凡遇到不能平稳慢速运动的情况，相机是不是全局快门就显得至关重要。当然无人机可以通过机械防抖消除一部分因为无人机震动导致的相机捕捉画面糊的情况，可是额外增加了硬件设施；手持手机拍摄通过软件方案（利用MEMS和图像学等知识）来把原始图像矫正回来，可是裁剪了画面大小。
- 各方面的权衡：理想的相机是高帧率，高进光率，高分辨率，无畸变，大视场角。可是现实往往不可能全部达到，高帧率和高进光率本身是矛盾的，无畸变和大视场角也是矛盾的，事实往往是在保证高帧率和无畸变的情况下尽可能满足其他条件。
- 相机数量：一般获取3D信息最好是双目及以上，单目摄像头更适合看图出一些简单特效，而且这些特效对深度和贴合度要求不高。但是多目摄像头就对计算单元的压力比较大，一般通过FPGA或者GPU加速实现实时计算输出。如果是固定的室内场景（非空旷大场馆，有大量透明玻璃窗这种极端情况），双目其实满足要求。
- RGBD SLAM？这个在之前深度传感器部分讨论过，个人认为并不需要。当然它肯定能减小双目SLAM的计算量，RGBD相机普遍在室外表现效果不佳，更多用于室内环境。
 
## IMU的作用不大
IMU+slam方案，理论上来说IMU提供了冗余的运动信息，通过数据融合可以得到更加精确的运动估计。

目前市面上的android手机多种多样，硬件越来越强大，使用人数也是最多，同时也有前人经验将orb-SLAM2移植到手机上的经验，移植过的人因该都知道，使用的时候，加载词袋模型需要花费7-8分钟时间，变成二进制文件也是缓慢，然后出来效果是每秒1-2帧（记不太请），慢的可以，然后果断放弃了。然后开始在手机端重写几乎所有算法，框架仿照ORB-SLAM2，以用来更加容易的适用手机的所有的特性，若是想要达到实时效果或者稍有延迟，只有两种路可以选择 1,降低图像的采样率 2,增加手机处理速度，面对需要用在实际中的项目，只有采用谦前者，果断采用每秒10帧采样，并对图像进行压缩，并使用多线程处理，结果效果不好，采样率只有再降，采样降低势必造成一些精度损失，只能使用其他传感器进行弥补，所以走到了多传感器融合的道路。

但为什么我觉得IMU的重要性其实不高？
- IMU适合运动平滑一些的情况，滤波可以预测设备下一秒的状态并且平滑轨迹，可是一方面人体移动速度大于大部分的机器人和手机，并且毫无规律，因此滤波的重要性几乎为0。
- 事实上是平滑运动时候IMU数据反而会增加误差，就拿Vins-SLAM而言，在慢速运动时候加入 IMU 的版本均不如原始双目版本的精度。应该是原始 VO 的优化已经比较彻底，IMU 误差项的加入给优化结果造成了更多的不稳定性。这一点在作者论文中也能看到，加入 IMU 的版本并没有比原始相机精度更高。
- 但是在快速运动的时候，相机方案可能完全失灵，IMU可以减少一些丢失，虽然精度上不是特别理想但总比丢失好；
- IMU提供重力分量？首先加速度仪在静止的时候的确可以计算出重力加速度的放下，可是有谁带着设备一动不动呢？另外由于运动时候加速度仪提供的数据是物体运动加速度加重力的叠加，而加速度仪噪音极大并且存在延时，要想从中分解出一个重力方向，不太现实。

总之，IMU是一个不错的低成本辅助传感器，但在使用的时候一定是分场合使用的，并且开发人员最好对SLAM的技术有大量的经验，才能知道什么时候用怎么用才能避开IMU带来的弊端。

# 头戴式SLAM的算法和传统SLAM算法区别
## 传统SLAM
一般SLAM算法包括以下步骤：1）传感器信息读取。 2）视觉里程计 (Visual Odometry, VO)。3）后端优化（Optimization）。4）回环检测（Loop Closing）。5）建图（Mapping）。

假如同时运行以上五个算法，势必对处理单元造成压力，然而在头戴式MR设备上我们其实只需要选择1，2和3步骤就可以，有时候3也没必要。
## 头戴式SLAM
这里的原因我们从SLAM最初的动机开始聊起，SLAM一开始是辅助机器人在位置环境里建图并且定位的，可是人类生活在一个完全已知的环境，我们完全可以先把已知的环境数据输入设备让机器记住这个有尺度的地图，这个就相当于提前完成建图和回环检测步骤。 

再谈步骤3，我们需要思考设备应用场景。假如是局部位置出现特效然后一闪而过，接下来随着用户行走，出现的新特效和之前毫无关联，那为什么我们要做后端优化呢？后端优化的步骤只是把不同时刻的轨迹和地图优化，现在地图不需要优化，前后时刻的特效也无关联。当然，如果特效有事件前后的属性，步骤三可以在时间连续性上起到作用。

结论：头戴式SLAM重点在于先把步骤一二做稳定，然后将产品往步骤三上优化，这样大大简化了计算量。

# 手机端对比头戴式混合现实
头戴式的确是可以加深度传感的，但是我们需要思考落地场景有什么区别。
- 距离：手机端要求用户和手机距离够近，并且现在主要是应用在人脸和手势识别，以及物件扫描。 而对于头戴式设备，手和设备的距离要更远，那么对深度传感器精度要求更高，成本也就上去，设备配置也上去了。
- 贴合度：其中有一个最不可以忽略的技术就是虚拟和现实的贴合度。可以说手机端是没有这个烦恼的，因为本身就是在屏幕上渲染成2D画面，没有eye box，光波导，亮度高等技术壁垒。可是转换到头戴式MR就会涉及很多，要好的贴合度就要好的成像透镜甚至是眼球跟踪技术。
- 亮度：高亮度的虚拟物体体验感才好，但需要功耗高的光机同时会带来设备发热的问题，它是贴合人额头的，虽然现在有很多方案在硬件设计层面避规这个问题。在手机端由于手机壳隔离再加只是在机子边缘接触，那么感受并不会那么强烈。目前这块做的比较好的是Hololens2，针对不同光机方案我会之后额外再写一篇，在这写会显得过长。
- 实时性：同时还有异步时间扭曲（ATW）等技术来处理虚拟物体的渲染，头戴式不像手机，人的头部动作往往很迅速，这就对渲染实时的要求加大了，可以说Oculus在ATW技术上一直做在最前端。
- 兼容性：当安卓系统外接摄像头时，很多接口是需要许可证等处理，这就需要资本的运作参与，但手机端完全没这个考虑。

# 未完成
人多，夜晚？
手势算法压缩 vs 控制器
slam++
选特定场景逻辑:在自动驾驶没有做到完美的Inside-Out定位方案之前，移动端的SLAM是不可能适配任何场景的。
未来的方向：iot，云计算