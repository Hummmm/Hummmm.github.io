---
title: 小目标检测分析 
tags: DeepLearning
edit: 2019-11-20
categories: 技术类
status: Completed
mathjax: true
highlight: true
mermaid: true
description: 小目标检测的原因和训练技巧。经典的网络都是针对通用目标数据集来设计的解决方案，因此对于图像中的小目标来说，检测效果不是很理想。
---

# 小目标难检测原因
## 主要原因
- 网络的stride特性：小目标在原图中尺寸比较小，通用目标检测模型中，一般的基础骨干神经网络都有几次下采样处理，导致小目标在特征图的尺寸基本上只有个位数的像素大小，导致设计的目标检测分类器对小目标的分类效果差。
- 如果分类和回归操作在经过几层下采样处理的 特征层进行，小目标特征的感受野映射回原图将可能大于小目标在原图的尺寸，造成检测效果差。

## 其他原因
- 网络损失函数：小目标在原图中的数量较少, 现有的检测网络中OHEM之类的训练样本选择机制，在正负样本选择的时候对小目标并不是很友好；
- 训练集的分布（参考SNIP）：在COCO数据集中大目标和小目标的大小比值是比较大的，这就为网络适应目标带来了一定的困难；
 

#解决技巧

## 从图像或特征尺度的角度
+ data-augmentation.简单粗暴，比如将图像放大 ( 或用超分辨率，切图多次检测)，利用 image pyramid多尺度检测，最后将检测结果融合.缺点是操作复杂，计算量大，实际情况中不实用，无法装入GPU进行训练，因此单纯的升级并不有效。ao等[2017]首先下采样图像，然后利用强化学习训练基于注意力的模型，动态搜索图像中感兴趣的区域。然后对选定的区域进行高分辨率的研究，并可用于预测较小的目标。这避免了对图像中每个像素进行同等关注分析的需要，节省了一些计算成本。一些论文[Dai等，2016b，2017年，Singh和Davis, 2018年]在目标检测上下文中训练时使用图像金字塔，而[Ren et al.， 2017]在测试时使用。
+ 特征融合方法：FPN这些，多尺度feature map预测（特征金字塔、RNN思想、逐层预测）;
    + pc端

图像金字塔：较早提出对训练图片上采样出多尺度的图像金字塔。通过上采样能够加强小目标的细粒度特征，在理论上能够优化小目标检测的定位和识别效果。但基于图像金字塔训练卷积神经网络模型对计算机算力和内存都有非常高的要求。计算机硬件发展至今也难有胜任。故该方法在实际应用中极少。

逐层预测：该方法对于卷积神经网络的每层特征图输出进行一次预测，最后综合考量得出结果。同样，该方法也需要极高的硬件性能
    + 移动端：

特征金字塔：参考多尺度特征图的特征信息，同时兼顾了较强的语义特征和位置特征。该方法的优势在于，多尺度特征图是卷积神经网络中固有的过渡模块，堆叠多尺度特征图对于算法复杂度的增加微乎其微。

浅网络。小物体更容易被接受场较小的探测器预测。较深的网络具有较大的接受域，容易丢失关于较粗层中较小对象的一些信息。Sommer等[2017b]提出了一种非常浅的网络，只有四个卷积层和三个完全连接的层，用于检测航空图像中的目标。当期望的实例类型很小时，这种类型的检测器非常有用。但是，如果预期的实例具有不同的大小，则效果更好
    + 理论层次：

RNN思想：参考了RNN算法中的门限机制、长短期记忆等，同时记录多层次的特征信息（注：和特征金字塔有本质区别）。但RNN固有的缺陷是训练速度较慢（部分操作无法矩阵化）

利用GAN将小物体放大再检测，CVPR2018有这样的论文;用生成对抗网络(GAN)来做小目标检测：Perceptual Generative Adversarial Networks for Small Object Detection。超分辨率。还有针对小目标的图像增强等。最典型的是利用生成对抗性网络选择性地提高小目标的分辨率。它的生成器学会了将小对象的不佳表示增强为超分辨对象，这些超分辨对象与真实的大对象非常相似，足以欺骗竞争的鉴别器。

利用context信息，建立object和context的联系，比如relation network;上下文信息。利用围绕小对象实例的上下文。Gidaris和Komodakis [2015]， Zhu等[2015b]使用上下文来提高性能，Chen等[2016a]则专门使用上下文来提高小对象的性能。他们使用上下文补丁对R-CNN进行了扩展，与区域建议网络生成的建议补丁并行。Zagoruyko等人[2016]将他们的方法与深度掩模对象建议相结合，使信息通过多条路径流动。

+ 备注：SSD是一种基于全卷积的网络的检测器，用不同层检测不同大小的物体。这中间有个矛盾，前面的featmap大，但semantic不够，后面的sematic够了，但经过太多的pooling，featmap太小了。要检测小物体，既需要一张足够大的featmap来提供更加精细的特征和做更加密集的采样，同时也需要足够的semantic meaning来与背景区分开。但如果将最后的featmap放大接上前面的话，是不是能够改善性能，FPN产生。

## 合适的训练方法：
- CVPR2018的SNIP以及SNIPER;参考SNIP区分大小目标，针对性优化；
- 在Augmentation for small object detection文章中提到增加图像中小目标的数量（不影响其它目标检测的情况下，复制小目标多个），提升小目标被学习到的机会；2）增加小目标图像在训练数据集中的数量，保证小目标能够被有效地学习；

## 在对小目标的IoU阈值上
对小目标可以不使用严苛的阈值（0.5），可以考虑针对小目标使用Cascade RCNN的思想，级联优化小目标的检测。
##回归损失函数上
- 在YOLO中按照不同的目标大小给了不同的损失函数加权系数：(2−w∗h)∗1.5(2-w*h)*1.5(2−w∗h)∗1.5。使用这样的策略其性能提升了1个点。
- 有密集遮挡，如何把location 和Classification 做的更好，参考IoU loss, repulsion loss等.
## 从anchor角度
+ anchor的密度：由检测所用feature map的stride决定，这个值与前景阈值密切相关，在密集的情况下可以使anchor加倍以增加对密集目标的检测能力（TextBoxes++，Pixel-Anchor）；
+ anchor的范围：
    + RetinaNet中是anchor范围是32~512，这里应根据任务检测目标的范围确定，按需调整anchor范围，或目标变化范围太大如MS COCO，这时候应采用多尺度测试；设置更小更稠密的anchor，
    + 设计anchor match strategy等，参考S3FD;
+ anchor的形状数量：RetinaNet每个位置预测三尺度三比例共9个形状的anchor，这样可以增加anchor的密度，但stride决定这些形状都是同样的滑窗步进，需考虑步进会不会太大，如RetinaNet框架前景阈值是0.5时，一般anchor大小是stride的4倍左右；
 
各种参考文献简介：https://blog.csdn.net/wq604887956/article/details/83053927
