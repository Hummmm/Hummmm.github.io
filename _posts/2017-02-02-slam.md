---
title: SLAM流程
tags: slam
edit: 2017-02-02
categories: 技术类
status: Completed
mathjax: true
highlight: true
mermaid: true
description: 主要是针对ORB-SLAM2的流程进行理解
---
# 局部建图

## Local mapping的目的是什么？
当机器在初始化定位以后，它需要不断实时告诉自己所处的新位置。可是随着运动机器跟踪到的已知特征会越来越少，尤其是运动剧烈和有遮挡的时候。此外机器还会因为某些地方特征相似而跟踪错误。那么就机器需要实时构建新的环境特征并且建立错误跟踪监测机制，提高自己的定位准确度，这就是local mapping。

## 怎么剔除掉错误的跟踪特征点？
由于机器在运动，靠每帧新建立出来的特征点信息准确度不够高，大部分是和之前检测到的特征重复，因此需要一个强有力的匹配算法，比如BOW词袋模型匹配算法。
再者，可以利用双目或多目视角估计特征的空间位置，由于像素在图像中的位置非连续，它的位置精度取整，这会导致越远的特征点的位置精确度越低，这会不利于新地图的构建，进而影响机器定位。因此针对远点，我们往往要利用多帧视差计算来减少特征位置误差。可是这样并不能保证所有的特征位置准确，在后续的过程中，我们可以用极线限制，反投影，尺度一致等反复测试这些特征点是不是足够准确。
最后我们还要求某个特征点相关联的关键帧个数至少大于3（经验值），并且可以根据之前的相机姿态来估计哪些帧可以看到这个新的特征点，我们往往要求至少过去的帧里至少有四分之一可以检测到这个特征点。

## 用经过剔除以后的特征点怎么进行相机估计？
我们应该持有一个原则，就是尽可能多的利用匹配点来提高机器姿态估计准确度。一个办法就是将过滤一轮后的新特征点所涉及到的关键帧特征充分利用起来一起优化，没有匹配到的新特征点继续保持固定。值得注意的是有一个技巧处理，远处的特征点在估计旋转时权重更大，近处的特征点在估计平移和尺度的时候权重更大。

## 为什么Local mapping带来什么副作用可以靠Local BA解决？
随着时间的推移，不断增加的特征点和关键帧会增加系统复杂度，优化的速度也放慢下来。我们可以通过筛选冗余的关键帧来缓解内存压力。如果仔细观察，我们会发现很多关键帧的信息是重复的，经验上几乎九成的点可以通过其他3个关键帧看到（作者定义KFs之间连接的方式是共同看到的map points个数，一个共视map point定义为一个edge。当edge个数大于15时，表示两帧存在连接关系）。因此我们要尽可能提高关键帧之间的视差，来保证每个关键帧携带足够的特征信息又不重复。

此外，我们可以选择局部优化来代替前期的全局优化，Local BA 这个时候就起到作用了。我们把局部优化的频率增加，全局优化的频率下降，分成两个线程来保证定位的实时性。

还有一个技巧就是当某个时刻机器进入一个纹理相对多的环境，它检测到的新特征点足够多，这时候我们甚至可以暂时关掉建图功能不再检测新的特征点，只做定位运算。

# 回环检测
## 除了BA优化，还有其他什么技术来改善相机长时间的定位问题？
 Loop closng是为了修正因为相机的长时间移动而带来的估计错误，时间的长短可以用关键帧个数来度量。回环检测可以从二维图像出发，也可以从三维点云出发。目前大家更推荐基于二维图像的方法。
通常规定当关键帧个数小于10的时候，Loop Closing是没有意义的。因为Loop closing是用来修正整体的估计错误，总关键帧10时本质和局部地图一样。

Orb-SLAM将Loop closing识别转化为模式识别，即只选取和当前帧相似的关键帧。利用BoW数据库，搜寻各关键帧和当前关键帧的相似分数和这些分数中最大值，只有分数>最大值*0.8的关键帧保留下来。

另外,在代码里作者针对识别过程中的运行速度和鲁棒性进行参数调整。运行速度只考虑当前帧的邻居帧。既然是回路检测，那么关键帧中与当前机器地理位置过远的部分就不需要考虑。作者认为当edges超过30个的，则认为这了两个关键帧是邻居关系。
 利用共视连续性(co-visibility consistency，即相邻关键帧之间至少有一个edge)提高鲁棒性，。作者认为既然相机回到了原路径的某一处，那么至少该处有不止一帧的特征和当前帧相似,只考虑连续的三帧作为loop candidates. 但是作者发现即使在这样的限制条件下，依旧会有好几组候选.因此他计算这些候选中的最高相似得分，规定候选与当前KF的相似得分应都大于最大值*0.75。   
从上述讨论来看，在不破坏作者整体思路的情况下，我们可以通过修改0.8，0.75这些参数来针对不同场景进行不同的调整，使得参数更适合小场景情况。

但要注意，BoW只用来快速筛选图像，后续需要通过其它方法一一验证、严格验证！如果回环选错了，那后面计算全错了，比如可以利用两帧之间（包括相邻位置）的三维点云匹配去验证回环。目前随着深度学习的方法普及，我们可以用分类的方式代替Bow，比如CNN，Auto-encoder,etc.

## 可以评价一下BOW吗？
由于DBoW将词典组织成树的形式，方便搜索，搜索速度飞快。而且词典是离线的，更适合大量的应用。不过如果应用场景特殊就需要额外训练自己的BOW词典。  而且BOW是利用分类算法把特征分类，不太考虑特征之间的几何关系。并且BOW不适合场景特征少或者重复特征太多的情况。

## 回环如何优化的？
对每个候选的回环帧，作者先匹配其和当前帧上的特征点，然后用特征点对应的三维点去求解一个相似变换矩阵（RANSAC框架下）。如果某个回环帧对应的矩阵有足够多的内点，那去做Sim3优化。利用优化结果再去寻找更多的特征匹配，再做一遍优化。如果内点足够多，那么接受这个回环。

## 如何评估回环检测好坏？
Precision-recall curve，简单点讲就是希望准确率和召回率都很低。

# 硬件选择
## 使用双目对Slam有什么提高？
双目解决了单目slam中的这些问题：
- 深度未知，导致scale of the map and estimated trajectory未知
- System Bootstrapping：用第一帧数据可以用来初始化map，不需要反复移动相机
- scale drift：单目slam存在scale drift的问题，尤其是pure rotations的时候
- 点云从sparse变成dense
- Full Bundle Adjustment：利用双目约束，在单目slam的基础上最后添加了full BA。
- Loop closing:在pose-graph optimization中，scale问题不存在，因此相似变换变成刚体变换 
- Localization Mode：定位的输入不仅有ORB，还有 matched stereo points，论文图示表明双目的结果比单目更加准确。
- 测距距离：单目<close stereo<far stereo


## 单目ORB-SLAM2 有哪些特性？
- 当分辨率过高和过低的时候，无法初始化
- 初始化的时候要保持低速运动，对准纹理丰富，一米以内的物体
- 在初始化完成以后可以在一米以外的区域也计算mappoint，但如果一开始相机对准的范围是1米以外的物体，无法初始化
- 只要特征点个数足够多，定位范围在2m以上（基线为双眼距离，即7cm左右）
- 在没有丢帧的情况下，姿态流畅没有跳变（从画出来的odometry粗略观察)
6.初始化之后对于纹理少的范围（低头抬头，地板或者天花板占画面一半以上）容易丢帧
7.旋转时容易丢帧，平移时不容易丢帧
8.丢帧以后回到原来初始化的姿态附近，很容易重新定位


ptam不具有的优点
place recognization（orb特征）、scale-aware loop closing和大场景的视图关联信息（遮挡之类的，local独立于全局，形成地图过程中需要人工干预。）
