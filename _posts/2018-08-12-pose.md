---
layout: post
title: '视觉三维人体姿态估计的实现难度和阶段性目标'
date: 2018-08-12
author: Jekyll
color: rgb(255,210,32)
cover: 'http://on2171g4d.bkt.clouddn.com/jekyll-banner.png'
tags: DeepLearning
---
写了一些3D human body reconstruction的项目经历，当时写的是英文想了下就不翻译了，还是保留一下原文的意思。

Considering the condition number of SVD used in the triangulation(Hartley & Zisserman, 2003), I need to avoid imperfect 2D keypoint matching affecting the depth estimate. Second, continuous learning allows me to know how innovation influences the result. For example, learning optimization problems let me add the constraint of 3D bone length and joint rotation angle to the process of triangulation so that the result is not so sensitive to the matching degree of 2d points. In addition, I also tried to use the optical flow model (e.g. flownet(Ilg et al., 2017) (Reda, Pottorff, Barker, & Catanzaro, 2017) ) and a classic human pose detection model(e.g. Hourglass(Alejandro Newell, 2016)) to do further binocular correspondence refinement and the temporal-spatial information between the adjacent frames, which not only solves the jitters of 2D key points(e.g. Openpose(Cao, Simon, Wei, & Sheikh, 2017) (Simon, Joo, Matthews, & Sheikh, 2017) (Wei, Ramakrishna, Kanade, & Sheikh, 2016)) but also guarantee 3D motion coherence even some joint positions are blocked for a short period of time. Therefore, I realize that the industry needs to weigh in all aspects to meet the requirements of low cost and high user experience, and constant innovation is more important than trading off when I want to meet higher requirements.

Alejandro Newell, J. D., Kaiyu Yang. (2016). Stacked hourglass networks for human pose estimation. In Eccv.

Cao, Z., Simon, T., Wei, S.-E., & Sheikh, Y. (2017). Realtime multi-person 2d pose estimation using part affinity fields. In Cvpr.

Hartley, R., & Zisserman, A. (2003). Multiple view geometry in computer vision (2nd ed.). New York, NY, USA: Cambridge University Press.

Ilg, E., Mayer, N., Saikia, T., Keuper, M., Dosovitskiy, A., & Brox, T. (2017, Jul). Flownet 2.0:

Evolution of optical flow estimation with deep networks. In Ieee conference on computer vision and pattern recognition (cvpr). Retrieved from http://lmb.informatik.uni-freiburg.de//Publications/2017/IMKDB17

Reda, F., Pottorff, R., Barker, J., & Catanzaro, B. (2017). flownet2-pytorch: Pytorch implementation of flownet 2.0: Evolution of optical flow estimation with deep networks. https://github.com/NVIDIA/flownet2-pytorch. GitHub.

Simon, T., Joo, H., Matthews, I., & Sheikh, Y. (2017). Hand keypoint detection in single images using multiview bootstrapping. In Cvpr.

Wei, S.-E., Ramakrishna, V., Kanade, T., & Sheikh, Y. (2016). Convolutional pose machines. In Cvpr.


最近几年基于关节型角色的建模和动画制作被视为一项艰巨的任务，当角色具有真实的人类外观时尤是如此，因为人物角色的正确表达需要处理多个问题。

# 原因

首先：人物角色的外观已为人们所熟知，这使得每个人都成为了苛刻的观察员，稍有不自然，就会被迅速察觉。

其次，人体的结构尤其复杂，包含了200多块骨骼以及600多块肌肉，当对刚性链接肢体进行全方位建模时，工作量与工作难度就被大大增加。同时，躯体的可变性特征又进一步增加了建模的复杂性。

最后，由于文化，个性，遗传等因素的影响，人类的运动行为有着巨大的差异，这又再一次加大了建模的难度。

现阶段，创建逼真的人体形态和动作已被视为一项新的技术，其应用场景非常广泛。这项研究的短期目标是使这项技术能够应用于许多不同的领域，而长远目标则是开发一套符合电影制作要求的单目/双目运动捕捉系统。这些需求被定义为捕捉包括面部和身体在内的完整运动。而目前的技术主要关注的是基本的骨骼从正面的运动，而不是其他的运动（如手臂和脚的微妙旋转）。还有从侧面的姿态估计，以及当身体的某些部分没有被捕捉到时，如何猜测姿势。在目标实现上可以分三个阶段:
# 体态检测
PC端單目2D到移動端的2D。第一阶段是静态三维姿态估计，它常被用于医学领域，如身体健康状况检测，它可以检测病人脊椎是否正常，然后根据检测结果科学判断病人症状，并指导他们的加强肩颈的活动与治疗。值得注意的是，该技术不需要考虑遮挡，由于数据可以在特定情况下采集，所以佩戴时的情况较为宽松，实现起来也相对简单。
# 火柴人驅動
PC端從單幀雙目3D到單目3D，不存在時間上的動作連貫，再到可以視頻跟蹤實現轉身依舊動作連貫。第二阶段是动态三维姿态估计，常用于人机交互、身体游戏、运动分析等领域。它过去是由深度摄像头辅助的，比如kinect设备。现阶段已经有技术可以处理一定程度的闭塞和多人情况，但这项技术是基于简化的运动模型，省略了手指、脚趾和头部的运动捕捉。
# 含有人體形態的動補系統

PC端脚手精確（無指尖），但目前無法實時向實時優化。第三阶段是动态三维形状和姿态估计，它可以应用于需要对人体姿态进行高精度估计的领域，如3D电影制作等，以降低成本。因为这些领域对细节的要求极高，使得该技术需要考虑到人体的胖瘦形态，以及微小关节的运动。这便要求建模时不仅要考虑骨骼的运动，还要考虑整个人体的形状，这样才能将三维形状以像素级的精度投影到二维图像上。另外，骨骼的运动能否符合人体运动学的规律也是一个复杂的问题，單單只有火柴人就會導致敺動的模型出現身體部位之間穿模，四肢自旋出不自然的角度。目前有两种简化的方法来处理这个问题：一是用动作捕捉系统实时记录主要骨骼的旋转角度；另一个是用算法去逆推，比如逆运动学和对抗网络。再者皮肤的可见几何体是否精细取决于细节内容和底层内部结构，如骨骼和肌肉结构。因此，该阶段的技术要求是最复杂的也是最难去实现的。
附一份之前开题报告写的英文调研
Current human pose dataset(H3.6M,CMU MoCap,Human Eva,etc.) are collected before a green/red curtain, laking of a diversity of environment. So pre-processing techniques, such as background subtraction[17] and bounding box[7][2], are necessary to reduce input noise.
At present, different theories exist in the literature regarding each of the above targets. A common problem for all the goals is the ambiguity[18] of the human body posture; that is, the
same 2d image can represent multiple human body postures. To address this problem, traditionally, various viewing angles can realize full body reconstruction. While deep learning[13][14] replaces geometric methods by learning a large amount of prior information; the study found that singlepurpose 2d information already contains enough 3d information. Most of the previous studies estimated the 2D joints first and then reconstruct the 3D joints.
However, this would miss a lot of pixel-level information, such as when the leg steps forward or backward; the corresponding 2D joints may be the same. Recent advances in hybrid methods have facilitated the study of human shape and pose estimation[10][9][20][12]. The neural network estimates both the mesh surface and 2D joints while the 3D joints positions are calculated by traditional computer graphics algorithm(shown in Figure 2). Such methods can avoid self interpenetration, unnatural limb spin, and constrain the location of the bone within the skin. Although
other researchers[8][21][16] have used only 3D joints to express motion without shape expression, the methods they use just fit in the specific and narrow environment. Therefore, the utilization of 2D poses information which can be used not only as an additional source of information but also as a way to measure the accuracy by projecting the estimated 3D pose to the 2D image and comparing the error(shown in step B C of Figure 3). However, the increase in algorithm complexity hinders the real-time process.
Besides, there are many techniques to discard anthropometrically unnatural poses, such as excessive knee extension[1]. One is to use a priori body model which determines if the approach
will be model-based, one is to use the GAN network[10] to distinguish the end to end. Also,[15]is used to achieve the coherency of the action and the temporary occlusion. However, the former will have a delay problem. [6] use multi-view to avoid long term occlusion, bringing inconvenience when constructing the shooting environment.

[1] Federica Bogo, Angjoo Kanazawa, Christoph Lassner, Peter Gehler, Javier Romero, and Michael J Black. Keep it smpl: Automatic estimation of 3d human pose and shape from a single image. In European Conference on Computer Vision, pages 561–578. Springer, 2016.

[2] Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei, and Yaser Sheikh. OpenPose: realtime multi-person 2D pose estimation using Part Affinity Fields. In arXiv preprint arXiv:1812.08008, 2018.

[3] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence, 40(4):834–848, 2017.

[4] Özgün Çiçek, Ahmed Abdulkadir, Soeren S Lienkamp, Thomas Brox, and Olaf Ronneberger. 3d u-net: learning dense volumetric segmentation from sparse annotation. In International conference on medical image computing and computer-assisted intervention, pages 424–432. Springer, 2016.

[5] Jose Dolz, Ismail Ben Ayed, and Christian Desrosiers. Dense multi-path u-net for ischemic stroke lesion segmentation in multiple image modalities. In International MICCAI Brainlesion Workshop, pages 271–282. Springer, 2018.

[6] Junting Dong, Wen Jiang, Qixing Huang, Hujun Bao, and Xiaowei Zhou. Fast and robust multi-person 3d pose estimation from multiple views. 01 2019.

[7] Hao-Shu Fang, Shuqin Xie, Yu-Wing Tai, and Cewu Lu. RMPE: Regional multi-person pose estimation. In ICCV, 2017.

[8] Daniel Holden, Taku Komura, and Jun Saito. Phase-functioned neural networks for character control. ACM Transactions on Graphics (TOG), 36(4):42, 2017.

[9] Hanbyul Joo, Tomas Simon, and Yaser Sheikh. Total capture: A 3d deformation model for tracking faces, hands, and bodies. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8320–8329, 2018.

[10] Angjoo Kanazawa, Michael J Black, David W Jacobs, and Jitendra Malik. End-to-end recovery of human shape and pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7122–7131, 2018.

[11] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431–3440, 2015.

[12] Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael J Black. Smpl: A skinned multi-person linear model. ACM transactions on graphics (TOG), 34(6):248, 2015.

[13] Julieta Martinez, Rayat Hossain, Javier Romero, and James J. Little. A simple yet effective baseline for 3d human pose estimation. 2017.

[14] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to- fine volumetric prediction for single-image 3D human pose. In Computer Vision and Pattern Recognition (CVPR), 2017.

[15] Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 3d human pose estimation in video with temporal convolutions and semi-supervised training. arXiv preprint arXiv:1811.11742, 2018.

[16] Dario Pavllo, David Grangier, and Michael Auli. Quaternet: A quaternion-based recurrent model for human motion. arXiv preprint arXiv:1805.06485, 2018.

[17] Iasonas Kokkinos R{iza Alp Güler, Natalia Neverova. Densepose: Dense human pose estimation in the wild. arXiv, 2018.

[18] Vince Tan, Ignas Budvytis, and Roberto Cipolla. Indirect deep structured learning for 3d human body shape and pose prediction. 2018.

[19] Kuan-Lun Tseng, Yen-Liang Lin, Winston Hsu, and Chung-Yang Huang. Joint sequence learning and cross-modality convolution for 3d biomedical segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6393–6400, 2017.

[20] Donglai Xiang, Hanbyul Joo, and Yaser Sheikh. Monocular total capture: Posing face, body, and hands in the wild. arXiv preprint arXiv:1812.01598, 2018.

[21] He Zhang, Sebastian Starke, Taku Komura, and Jun Saito. Mode-adaptive neural networks for quadruped motion control. ACM Transactions on Graphics (TOG), 37(4):145, 2018.

[22] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2921–2929, 2016.
# 未來方向
3D pose移動端和微小关节的3D pose電腦端。由于有几个相关项目在进行就省略了。



